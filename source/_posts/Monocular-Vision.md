---
title: Monocular-Vision
top: false
cover: false
toc: true
date: 2022-05-11 20:17:31
password:
summary:
description:
categories:
- Monocular Vision
tags:
- Monocular Vision
---

# 单目视觉研究方向

单目视觉研究方向很多，包括但不限于：

1）基于单目视觉的同时定位与地图构建方法；

2）基于单目视觉的车距测量方法；

3）基于单目视觉的定位方法；

4）基于单目视觉的三维重建算法；

5）基于单目视觉的深度估计方法；

6）基于单目视觉的路面车辆检测及跟踪方法；

7）基于单目视觉的道路图像理解……



# 基于单目视觉的深度估计算法

## 视觉系统

单目视觉 --> 只是用一个视觉传感器（摄像机），其在成像过程中从三维客观世界投影到二维图像，损失了深度信息。单目视觉系统结构简单，算法成熟，计算量较小。

双目立体视觉 --> 双目视觉系统由两个摄像机组成，利用 <font color=green>三角测量原理</font> 获得场景的深度信息，并可重建周围景物的三维形状和位置，类似于人眼功能。

多目视觉 --> 多目视觉系统由三个及三个以上摄像机组成，主要用来解决双目立体视觉中匹配多义性问题，提高匹配精度。

全景视觉 --> 具有较大水平视场的多方向成像系统，视场可达360度。全景视觉系统可通过图像拼接方式或者折反射光学元件实现。

混合视觉系统 --> 由两种或两种以上视觉系统组成，

## 深度估计



> 深度估计可应用于机器人导航、增强现实、三维重建、自动驾驶等领域。
>
> <font color=green>目前，大部分深度估计都是基于二维RGB 图像到 RBG-D (RGB + depth map，depth map 类似于灰度图像，只是它的每个像素值是传感器距离物体的实际距离) 图像的转化估计，主要包括从图像明暗、不同视角、光度、纹理信息等获取场景深度形状的 shape from X 方法，还有结合 SFM(structure from motion) 和 SLAM(simultaneous localization and mapping) 等方式预测相机位姿的算法。</font>



> 直接用设备获取深度 --> 设备造假昂贵。
>
> 利用双目进行深度估计 --> 由于双目图像需要利用立体匹配进行像素点对应和视差计算，所以计算复杂度较高，尤其对低纹理场景的匹配效果不好。
>
> 单目深度估计 --> 相对成本更低，更容易普及。



> <font color=green>单目深度估计 </font>  --> 利用一张或者唯一视角下的 RGB 图像，估计图像中每个像素相对拍摄源的距离。



> 单幅图像深度估计模型方法和数据集：
>
> 数据集 -->按场景类型可分为：室内数据集，室外数据集，虚拟场景数据集
>
> 模型方法 --> 按数学模型的不同分为：基于传统机器学习的方法，基于深度学习的方法。
>
> <font color = green>1. 基于传统机器学习的单目深度估计方法</font>
>
> 该方法一般使用马尔可夫随机场（MRF）或条件随机场（CRF）建模深度关系，在最大后验概率框架下，通过能量函数最小化求解深度。
>
> 基于传统机器学习的单目深度估计方法 --> 依据模型是否包含参数分为：参数学习方法，非参数学习方法。
>
> <font color = green>参数学习方法</font> --> 假定模型包含未知参数，训练过程是对未知参数求解的过程；
>
> <font color = green>非参数学习方法 </font>--> 使用现有数据集进行相似性检索推测深度，不需要通过学习获得参数。
>
> <font color = green>2. 基于深度学习的单目深度估计方法</font>
>
> 基于深度学习的单目深度估计算法可大致分为以下几类：
>
> 1）<font color = green>监督算法</font> --> 以 2 维图像作为输入，以深度图作为输出进行训练
>
> 2）<font color = green>无监督算法</font> --> 仅使用两个摄像机采集的双目图像数据进行联合训练。其双目数据可彼此预测对方，从而获得相应的视差数据，再根据视差与深度的关系进行演化。亦或将双目图像中各个像素点的对应问题看作立体匹配问题进行训练。
>
> <font color = green>由于深度数据的获取难度较高，所以目前大量算法都是基于无监督模型的。</font>

























